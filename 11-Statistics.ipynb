{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Statistics for Biologists\n",
    "This notebook will discuss **descriptive** and **inferential** statistics, and introduce ways to implement them in Python.\n",
    "\n",
    "### By the end of this notebook, you will be able to:\n",
    "* Identify when to use descriptive or inferential statistics\n",
    "* Apply the appropriate statistical tests to compare two groups\n",
    "* Use the stats package from SciPy to run simple tests in Python\n",
    "* Test direction selectivity differences in two Brain Observatory cell types\n",
    "\n",
    "### Table of Contents\n",
    "1. [Part One: Population vs sample distributions](#one)\n",
    "2. [Part Two: The Central Limit Theorem](#two)\n",
    "3. [Part Three: Skewed Distributions](#three)\n",
    "4. [Part Four: Hypothesis Testing](#four)\n",
    "5. [Part Five: Testing Direction Selectivity in the Brain Observatory](#five)\n",
    "6. [References & resources](#refs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"one\"></a>\n",
    "## Part One: Population vs sample distributions\n",
    "**Descriptive statistics** summarize the main features of a data set.\n",
    "\n",
    "It's important to distinguish between the following:\n",
    "* **Observation**: result from one trial of an experiment\n",
    "* **Sample**: results from multiple independent trials\n",
    "* **Population**: the *ground truth*; all possible observations that could be seen\n",
    "\n",
    "Distributions differ in their **location** (mean, $\\mu$) and **spread** (standard deviation, $\\sigma$). Below, we'll define a **population distribution** and plot it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Import our necessary toolboxes and tell matplotlib to plot inline\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Decide on a mean and a standard deviation\n",
    "mu, sigma = 3, 2\n",
    "\n",
    "# Use np.random.normal to create a distribution of 10,000 points with our given mu & sigma\n",
    "pop = np.random.normal(mu, sigma, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Plot a histogram with 30 bins\n",
    "# Giving it the argument density=True will plot normalized counts\n",
    "# This will create a probability density (rather than raw counts)\n",
    "plt.hist(pop, 30, density=True)\n",
    "plt.axvline(mu,color='r')\n",
    "plt.title('Population distribution of 10,000 points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There are various ways we can describe the distribution of the dataset, beyond the standard deviation:\n",
    "* Range (minimum and maximum)\n",
    "* Variance ($\\sigma^2$)\n",
    "* Standard Error of the Mean (S.E.M., $\\sigma/\\sqrt{n}$)\n",
    "* Confidence Intervals\n",
    "\n",
    "We can easily get many of these descriptive statistics by using the `scipy stats` package method `describe()`. [Documentation here.](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.describe.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "stats.describe(pop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We created a normal distribution from a mean of 3 but with limited points, so these values are *just* slightly off. You'll also notice that the variance is indeed our standard deviation (2) squared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Our variable `pop` is the \"ground truth\" population. However, we'll rarely have *10,000* datapoints in our sample. So, let's generate a more realistic sample, and see how the mean compares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Create a sample distribution with less data points\n",
    "sample_mean, sample_sigma = 3, 2\n",
    "sample = np.random.normal(sample_mean, sample_sigma, 20)\n",
    "\n",
    "# Plot our histogram, with alpha to 0.5 which will make the chart slightly transparent\n",
    "plt.hist(pop, 30, alpha=0.5, density=True)\n",
    "plt.hist(sample, 30, alpha=0.5, color='r',density=True)\n",
    "plt.axvline(np.mean(pop),color='blue') # Take the mean and plot a vertical blue line \n",
    "plt.axvline(np.mean(sample),color='red') # Take the mean and plot a vertical red line \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Look at the descriptive statistics of our sample\n",
    "print(stats.describe(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"two\"></a>\n",
    "## Part Two: The Central Limit Theorem\n",
    "\n",
    "With fewer samples, the mean of the sample distribution tends to be further from the mean of the population distribution. This is known as the **central limit theorem**, which states that the distribution of sample means will become increasingly close to a normal distribution as the sample size increases, regardless of the shape of the population distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,5,figsize=(20,5),sharey=True)\n",
    "\n",
    "mu = 0\n",
    "\n",
    "sample_means = []\n",
    "\n",
    "# For each subplot, create a plot.\n",
    "for a in range(len(ax)):\n",
    "    \n",
    "    # Make the sample size = to 3^(a+1)\n",
    "    sample_size = 3**(a+1)\n",
    "    \n",
    "    # Calculate the mean of sample of sample_size designated above, 10000 times\n",
    "    for x in range(10000):\n",
    "        sample_dist = np.random.normal(mu, 10, sample_size) # Create a normal distribution with mu, sigma\n",
    "        sample_means.append(np.mean(sample_dist)) # Append the mean of this distribution\n",
    "        \n",
    "    ax[a].hist(sample_means,color='teal',alpha = .5) # Plot the distribution of means\n",
    "    ax[a].set_title('sample size= '+ str(sample_size)+', mean = '+ str(np.round(np.mean(sample_means),3)))\n",
    "    ax[a].set_xlim([-20,20])\n",
    "    sample_means = [] # Reset the sample means\n",
    "\n",
    "plt.suptitle('Distributions of 10,000 sample means for a population with mean '+str(mu),fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"three\"></a>\n",
    "## Part Three: Skewed Distributions\n",
    "\n",
    "However, not every population in nature is **normally distributed**. In fact, most populations are slightly skewed. Let's demonstrate a population distribution and sample distribution that is drawn from a [gamma distribution](https://en.wikipedia.org/wiki/Gamma_distribution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Create a skewed distribution of 10,000 points with our given mu & sigma\n",
    "pop_size = 10000\n",
    "sample_size = 100\n",
    "\n",
    "skewed_pop = np.random.gamma(7.5,1,pop_size)\n",
    "skewed_sample = np.random.gamma(7.5,1,sample_size)\n",
    "\n",
    "pop_stats = stats.describe(skewed_sample)\n",
    "sample_stats = stats.describe(skewed_pop)\n",
    "\n",
    "plt.hist(skewed_pop, 30, alpha = .3, density=True)\n",
    "plt.hist(skewed_sample, 30, alpha = .3, density=True)\n",
    "plt.axvline(pop_stats.mean,color='blue')\n",
    "plt.axvline(sample_stats.mean,color='orange') # plot the mean of the sample\n",
    "\n",
    "plt.legend(['Population','Sample'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You might notice that with this skewed population, the mean is a pretty poor descriptor of both distributions. **When the skew is bad (*statistically bad*), we should report the median.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Important notes:\n",
    "* <code>stats.describe()</code> doesn't give us the median (annoyingly) but `np.median()` can!\n",
    "* The `stats.skewtest()` method ([documentation here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.skewtest.html#scipy.stats.skewtest)) implements the <a href=\"https://www.jstor.org/stable/2684359?seq=1\">D'Agostino-Pearson skewness test</a>, one of many different tests (e.g., the Kolmogorov-Smirov test) that can be used to check the normality of a distribution.\n",
    "    * This code can return a statistic as well as a pvalue, if you designate it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\"><b>Tasks</b>:\n",
    "\n",
    "1. Rework the code directly above so that if the skew is significant (you can use <code>stats.skewtest()</code> for that!), plot and report the <b>median</b> instead of the mean.\n",
    "2. Rework our demonstration of the central limit theorem for a skewed, rather than a normal, population. Does the theorem still hold?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"four\"></a>\n",
    "## Part Four: Hypothesis Testing\n",
    "\n",
    "**Inferential statistics** generalize from observed data to the world at large\n",
    "\n",
    "\n",
    "Most often, the goal of our hypothesis testing is to test whether or not two distributions are different, or if a distribution has a different mean than the underlying population distribution.\n",
    "\n",
    "With the normal sample population we generated above, our **null hypothesis** is that the mean of our sample distribution is equal to 3. We want to test the probability that this is not true. Since we know our distributions are normal (they're generated from a normal distribution!) we can use **parametric statistics** to test our hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The SciPy stats package has [many hypothesis testing tools](https://docs.scipy.org/doc/scipy/reference/stats.html) (see Statistical Tests). First, we can use a one-way t-test to ask whether our population has a mean different than three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sample_mean, sample_sigma = 3, 2\n",
    "sample_pop = np.random.normal(sample_mean, sample_sigma, 20)\n",
    "stats.ttest_1samp(sample_pop,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Not surprisingly, if we create a normal distribution of mean 3, the distribution is not likely to be different than 3. However, what happens if we change the mean, standard deviation, or sample size?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In most cases, we will be testing whether or not two distributions are different from eachother. In order to do so, we can use the independent t-test in our stats package: `stats.ttest_ind()`. If we had paired samples, we would use a dependent t-test [as seen here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_rel.html#scipy.stats.ttest_rel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Create two distributions and test whether they're different\n",
    "pop_1 = np.random.normal(3,2,20)\n",
    "pop_2 = np.random.normal(5,2,20)\n",
    "\n",
    "stats.ttest_ind(pop_1,pop_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If one of our populations is skewed, however, we **cannot use a t-test**. A t-test assumes that the populations are normally distributed. For skewed populations, we can use either the [Mann-Whitney U](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mannwhitneyu.html#scipy.stats.mannwhitneyu) (for independent samples, `stats.mannwhitneyu()`) or the [Wilcoxon Signed Rank Test](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.wilcoxon.html#scipy.stats.wilcoxon) (for dependent/paired samples,`stats.wilcoxon()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "skewed_pop = np.random.gamma(7.5,1,10000)\n",
    "comparison_pop = np.random.normal(8,2,20)\n",
    "\n",
    "stats.mannwhitneyu(skewed_pop,comparison_pop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"five\"></a>\n",
    "## Part Five: Testing Direction Selectivity in the Brain Observatory\n",
    "\n",
    "Let's work with some real data to apply what we've learned above. Below, we'll create our BrainObservatoryCache instance and look at the possible cre_lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas & the necessary module from the AllenSDK\n",
    "import pandas as pd\n",
    "from allensdk.core.brain_observatory_cache import BrainObservatoryCache\n",
    "\n",
    "# Create an instance of the Brain Observatory Cache as an object, \"boc.\"\n",
    "boc = BrainObservatoryCache(manifest_file='/datasets/allen-brain-observatory/visual-coding-2p/manifest.json')\n",
    "\n",
    "cre_lines = boc.get_all_cre_lines()\n",
    "print(cre_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a longstanding debate over whether inhibitory cells in cortex are as direction selective as excitatory cells in cortex. Let's compare the direction selectivity of two different Cre lines: Emx1-Cre, [which marks excitatory cells in cortex](https://www.jneurosci.org/content/22/15/6309) and PV-Cre, which marks most of the inhibitory cells in cortex.\n",
    "\n",
    "<div class=\"alert alert-success\"><b>Task</b>: Get the experiment containers with <code>get_experiment_containers(targeted_structures=[],cre_lines=[])</code> for all experiments in VISp for the Emx1-IRES-Cre and Pvalb-IRES-Cre lines, convert them to Pandas dataframes, and assign them to <code>emx_df</code> and <code>pv_df</code>, respectively.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract experiment containers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now, we'll need to use the `get_cell_specimens()` method to extract all of the specimens with matching experiment container IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "emx_containers = list(emx_df['id'])\n",
    "emx_specimens = pd.DataFrame(boc.get_cell_specimens(experiment_container_ids=emx_containers))\n",
    "\n",
    "pv_containers = list(pv_df['id'])\n",
    "pv_specimens = pd.DataFrame(boc.get_cell_specimens(experiment_container_ids=pv_containers))\n",
    "\n",
    "emx_specimens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\"><b>Task</b>: Create a plot with two subplots. The left should be a histogram of our DSI values ('dsi_dg') for Emx1-Cre and PV-Cre cells. The right should be a boxplot of the DSI values ('dsi_dg').</div>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>Note</b>: The <code>boxplot</code> function is not happy when you give it data with NaN in it. You can use the <code>dropna()</code> method of a dataframe to reassign the 'dsi_dg' column and remove the NaN values.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\"><b>Task</b>: Determine whether these two samples of DSI values are statistically different! Write code that first checks whether or not the distributions are skewed, and then runs the appropriate statistics.\n",
    "    \n",
    "**Challenge**: Package this up into a handy function, which takes two distributions and runs the appropriate statistics on them.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"refs\"></a>\n",
    "## References & resources\n",
    "I *strongly* recommend reading the [Points of significance](https://www.nature.com/collections/qghhqm/pointsofsignificance) series from *Nature* which covers many of these topics. This lecture specifically focuses on [The Importance of Being Uncertain](https://www.nature.com/articles/nmeth.2613).\n",
    "\n",
    "For a demonstration on how to animate the central limit theorem, see [this Github notebook](https://github.com/rohanjoseph93/Central-Limit-Theorem/blob/master/Central%20Limit%20Theorem.ipynb).\n",
    "\n",
    "Consider working through the examples in [Inferential thinking](https://www.inferentialthinking.com/chapters/11/Testing_Hypotheses.html).\n",
    "\n",
    "This notebook borrows code from [Hypothesis tests in Python](https://datasciencechalktalk.com/2019/09/02/hypothesis-tests-with-python/) by Valentina Alto and ideas from a variety of other sources, including [Towards Data Science](https://towardsdatascience.com/hypothesis-testing-in-machine-learning-using-python-a0dc89e169ce)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
